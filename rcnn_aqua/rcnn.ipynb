{"cells":[{"cell_type":"markdown","metadata":{"editable":false},"source":["# Object Detection with Faster RCNN\n","\n","Code is for the following video: https://www.youtube.com/watch?v=Uc90rr5jbA4&t=71s\n","\n","Do give this notebook a thumbs-up if you liked it. Thanks!"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision import datasets, models\n","from torchvision.transforms import functional as FT\n","from torchvision import transforms as T\n","from torch import nn, optim\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, sampler, random_split, Dataset\n","import copy\n","import math\n","from PIL import Image\n","import cv2\n","import albumentations as A  # our data augmentation library\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import sys\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# remove arnings (optional)\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from collections import defaultdict, deque\n","import datetime\n","import time\n","from tqdm import tqdm # progress bar\n","from torchvision.utils import draw_bounding_boxes\n","\n","\n","from pycocotools.coco import COCO\n","from albumentations.pytorch import ToTensorV2"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["print(torch.__version__)\n","print(torchvision.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["def get_transforms(train=False):\n","    if train:\n","        transform = A.Compose([\n","            A.Resize(600, 600), # our input size can be 600px\n","            A.HorizontalFlip(p=0.3),\n","            A.VerticalFlip(p=0.3),\n","            A.RandomBrightnessContrast(p=0.1),\n","            A.ColorJitter(p=0.1),\n","            ToTensorV2()\n","        ], bbox_params=A.BboxParams(format='coco'))\n","    else:\n","        transform = A.Compose([\n","            A.Resize(600, 600), # our input size can be 600px\n","            ToTensorV2()\n","        ], bbox_params=A.BboxParams(format='coco'))\n","    return transform"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Dataset\n","\n","This is our dataset class. It loads all the necessary files and it processes the data so that it can be fed into the model."]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["base_dir = os.getcwd()\n","print(base_dir)\n","print()\n","\n","dataset_path = \"Aquarium Combined/\"\n","coco = COCO(os.path.join(base_dir, dataset_path, \"train\", \"_annotations.coco.json\"))\n","\n","categories = coco.cats\n","n_classes = len(categories.keys())\n","\n","classes = [i[1]['name'] for i in categories.items()]"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["from AquariumDetection import AquariumDetection\n","train_dataset = AquariumDetection(root=dataset_path, transforms=get_transforms(True))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["This is a sample image and its bounding boxes, this code does not get the model's output"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["sample = train_dataset[2]\n","img_int = torch.tensor(sample[0] * 255, dtype=torch.uint8)\n","plt.imshow(draw_bounding_boxes(\n","    img_int, sample[1]['boxes'], [classes[i] for i in sample[1]['labels']], width=4\n",").permute(1, 2, 0))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Model\n","\n","Our model is FasterRCNN with a backbone of `MobileNetV3-Large`. We need to change the output layers because we have just 7 classes but this model was trained on 90 classes."]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","\n","# lets load the faster rcnn model\n","model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","in_features = model.roi_heads.box_predictor.cls_score.in_features # we need to change the head\n","model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, n_classes)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["This is our collating function for the train dataloader, it allows us to create batches of data that can be easily pass into the model"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["from utils import collate_fn\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, collate_fn=collate_fn)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["The following blocks ensures that the model can take in the data and that it will not crash during training"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["images,targets = next(iter(train_loader))\n","images = list(image for image in images)\n","targets = [{k:v for k, v in t.items()} for t in targets]\n","output = model(images, targets) # just make sure this runs without error"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Optimizer\n","\n","Here, we define the optimizer. If you wish, you can also define the LR Scheduler, but it is not necessary for this notebook since our dataset is so small.\n","\n","> Note, there are a few bugs with the current way `lr_scheduler` is implemented. If you wish to use the scheduler, you will have to fix those bugs"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, nesterov=True, weight_decay=1e-4)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Training\n","\n","The following is a function that will train the model for one epoch. Torchvision Object Detections models have a loss function built in, and it will calculate the loss automatically if you pass in the `inputs` and `targets`"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["device = torch.device(\"cpu\") # use GPU to train\n","def train_one_epoch(model, optimizer, loader, device, epoch):\n","    model.to(device)\n","    model.train()\n","    \n","    all_losses = []\n","    all_losses_dict = []\n","    \n","    for images, targets in tqdm(loader):\n","        images = list(image.to(device) for image in images)\n","        targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n","        \n","        loss_dict = model(images, targets) # the model computes the loss automatically if we pass in targets\n","        losses = sum(loss for loss in loss_dict.values())\n","        loss_dict_append = {k: v.item() for k, v in loss_dict.items()}\n","        loss_value = losses.item()\n","        \n","        all_losses.append(loss_value)\n","        all_losses_dict.append(loss_dict_append)\n","        \n","        if not math.isfinite(loss_value):\n","            print(f\"Loss is {loss_value}, stopping trainig\") # train if loss becomes infinity\n","            print(loss_dict)\n","            sys.exit(1)\n","        \n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","        \n","    all_losses_dict = pd.DataFrame(all_losses_dict) # for printing\n","    print(\"Epoch {}, lr: {:.6f}, loss: {:.6f}, loss_classifier: {:.6f}, loss_box: {:.6f}, loss_rpn_box: {:.6f}, loss_object: {:.6f}\".format(\n","        epoch, optimizer.param_groups[0]['lr'], np.mean(all_losses),\n","        all_losses_dict['loss_classifier'].mean(),\n","        all_losses_dict['loss_box_reg'].mean(),\n","        all_losses_dict['loss_rpn_box_reg'].mean(),\n","        all_losses_dict['loss_objectness'].mean()\n","    ))"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["10 Epochs should be enough to train this model for a high accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["num_epochs=10\n","\n","for epoch in range(num_epochs):\n","    train_one_epoch(model, optimizer, train_loader, device, epoch)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Trying on sample Images\n","\n","This is the inference code for the model. First, we set the model to evaluation mode and clear the GPU Cache. We also load a test dataset, so that we can use fresh images that the model hasn't seen."]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["model.eval()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["test_dataset = AquariumDetection(root=dataset_path, split=\"test\", transforms=get_transforms(False))\n","\n","img, _ = test_dataset[5]\n","img_int = torch.tensor(img*255, dtype=torch.uint8)\n","with torch.no_grad():\n","    prediction = model([img.to(device)])\n","    pred = prediction[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["fig = plt.figure(figsize=(14, 10))\n","plt.imshow(draw_bounding_boxes(img_int,\n","    pred['boxes'][pred['scores'] > 0.8],\n","    [classes[i] for i in pred['labels'][pred['scores'] > 0.8].tolist()], width=4\n",").permute(1, 2, 0))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1849949,"sourceId":3020523,"sourceType":"datasetVersion"}],"dockerImageVersionId":30154,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
